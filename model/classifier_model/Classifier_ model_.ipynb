{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mô hình: https://www.kaggle.com/code/vangphamhuu/classifier-model?scriptVersionId=226940874"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cài đặt và import thư viện"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-10T15:52:54.782186Z",
     "iopub.status.busy": "2025-03-10T15:52:54.78198Z",
     "iopub.status.idle": "2025-03-10T15:53:00.786198Z",
     "shell.execute_reply": "2025-03-10T15:53:00.785337Z",
     "shell.execute_reply.started": "2025-03-10T15:52:54.782167Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "!pip install -q underthesea"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-10T15:58:24.11762Z",
     "iopub.status.busy": "2025-03-10T15:58:24.11726Z",
     "iopub.status.idle": "2025-03-10T15:58:24.636631Z",
     "shell.execute_reply": "2025-03-10T15:58:24.635976Z",
     "shell.execute_reply.started": "2025-03-10T15:58:24.117587Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import json\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "from PIL import Image\n",
    "import underthesea\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import models, transforms\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Đọc dữ liệu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-10T15:55:34.15773Z",
     "iopub.status.busy": "2025-03-10T15:55:34.15727Z",
     "iopub.status.idle": "2025-03-10T15:55:34.162556Z",
     "shell.execute_reply": "2025-03-10T15:55:34.161732Z",
     "shell.execute_reply.started": "2025-03-10T15:55:34.157707Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def load_image_caption(caption_path):\n",
    "    with open(caption_path, 'r', encoding=\"utf-8\") as f:\n",
    "        data_captions = json.load(f)\n",
    "\n",
    "    image_dict = {}\n",
    "    for item in data_captions:\n",
    "        image_path = item[\"path_file\"]\n",
    "        image_path = image_path.split(\"/\")\n",
    "        image_path = image_path[0] + \"/gen_caption(Nhap)\" + \"/\" + image_path[1] + \"/\" + image_path[2]\n",
    "        captions = item[\"captions\"] \n",
    "        \n",
    "        if image_path not in image_dict:\n",
    "            image_dict[image_path] = []\n",
    "        \n",
    "        image_dict[image_path].extend(captions)\n",
    "\n",
    "    return image_dict\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-10T15:55:34.164367Z",
     "iopub.status.busy": "2025-03-10T15:55:34.16408Z",
     "iopub.status.idle": "2025-03-10T15:55:34.195513Z",
     "shell.execute_reply": "2025-03-10T15:55:34.194775Z",
     "shell.execute_reply.started": "2025-03-10T15:55:34.164346Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def split_data(image_dict, train_ratio=0.7, val_ratio=0.15, test_ratio=0.15):\n",
    "    image_paths = list(image_dict.keys())\n",
    "    random.shuffle(image_paths)\n",
    "    \n",
    "    train_images, temp_images = train_test_split(image_paths, test_size=(1 - train_ratio), random_state=42)\n",
    "    val_images, test_images = train_test_split(temp_images, test_size=(test_ratio / (val_ratio + test_ratio)), random_state=42)\n",
    "\n",
    "    train_data = [(img, cap) for img in train_images for cap in image_dict[img]]\n",
    "    val_data = [(img, cap) for img in val_images for cap in image_dict[img]]\n",
    "    test_data = [(img, cap) for img in test_images for cap in image_dict[img]]\n",
    "\n",
    "    return train_data, val_data, test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-10T15:55:34.196538Z",
     "iopub.status.busy": "2025-03-10T15:55:34.196327Z",
     "iopub.status.idle": "2025-03-10T15:55:34.243551Z",
     "shell.execute_reply": "2025-03-10T15:55:34.242745Z",
     "shell.execute_reply.started": "2025-03-10T15:55:34.196521Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "image_dict = load_image_caption(\"/kaggle/input/imagecaptioning/output.json\")\n",
    "train_data, val_data, test_data = split_data(image_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tiền xử lý ảnh + văn bản"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-10T16:15:43.650518Z",
     "iopub.status.busy": "2025-03-10T16:15:43.650159Z",
     "iopub.status.idle": "2025-03-10T16:15:43.664303Z",
     "shell.execute_reply": "2025-03-10T16:15:43.663381Z",
     "shell.execute_reply.started": "2025-03-10T16:15:43.650483Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "\n",
    "class ImageCaptionDataset(Dataset):\n",
    "    def __init__(self, image_root, captions_file, transform=None, max_length=50):\n",
    "        self.transform = transform\n",
    "        self.max_length = max_length\n",
    "\n",
    "        with open(captions_file, 'r', encoding=\"utf-8\") as f:\n",
    "            data_captions = json.load(f)\n",
    "        \n",
    "        # Tạo danh sách ảnh & captions\n",
    "        self.annotations = {}\n",
    "        self.class_labels = {}\n",
    "        \n",
    "        for item in data_captions:\n",
    "            image_path = item[\"path_file\"]\n",
    "            image_path = image_path.split(\"/\")\n",
    "            full_img_path = image_root + \"/\"+ image_path[0] + \"/gen_caption(Nhap)\" + \"/\" + image_path[1] + \"/\" + image_path[2]\n",
    "            self.annotations[full_img_path] = item[\"captions\"]\n",
    "            \n",
    "            # Lấy nhãn phân loại từ thư mục cha của ảnh\n",
    "            class_label = image_path[1]  # Giả sử thư mục thứ 2 là nhãn\n",
    "            self.class_labels[full_img_path] = class_label\n",
    "        \n",
    "        self.img_ids = list(self.annotations.keys())\n",
    "\n",
    "        # Xây dựng danh sách nhãn phân loại\n",
    "        self.unique_classes = list(set(self.class_labels.values()))\n",
    "        self.class_to_idx = {cls: idx for idx, cls in enumerate(self.unique_classes)}\n",
    "\n",
    "        # Xây dựng từ điển từ captions\n",
    "        self.vocab = self.build_vocabulary()\n",
    "\n",
    "    def build_vocabulary(self, threshold=4):\n",
    "        \"\"\"\n",
    "        Xây dựng từ điển từ các caption\n",
    "        \"\"\"\n",
    "        counter = Counter()\n",
    "        \n",
    "        for captions in self.annotations.values():\n",
    "            for caption in captions:\n",
    "                tokens = underthesea.word_tokenize(caption.lower())  # Dùng Underthesea để tách từ\n",
    "                counter.update(tokens)\n",
    "        \n",
    "        words = [word for word, count in counter.items() if count >= threshold]\n",
    "        \n",
    "        vocab = {'<pad>': 0, '<start>': 1, '<end>': 2, '<unk>': 3}\n",
    "        vocab.update({word: idx + 4 for idx, word in enumerate(words)})\n",
    "        \n",
    "        return vocab\n",
    "\n",
    "    def caption_to_indices(self, caption):\n",
    "        \"\"\"\n",
    "        Chuyển đổi caption thành chuỗi indices\n",
    "        \"\"\"\n",
    "        tokens = underthesea.word_tokenize(caption.lower())  # Dùng Underthesea để tách từ\n",
    "        caption_indices = [self.vocab['<start>']] + \\\n",
    "                          [self.vocab.get(token, self.vocab['<unk>']) for token in tokens] + \\\n",
    "                          [self.vocab['<end>']]\n",
    "        \n",
    "        if len(caption_indices) > self.max_length:\n",
    "            caption_indices = caption_indices[:self.max_length]\n",
    "        else:\n",
    "            caption_indices += [self.vocab['<pad>']] * (self.max_length - len(caption_indices))\n",
    "        \n",
    "        return torch.tensor(caption_indices, dtype=torch.long)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_ids)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.img_ids[idx]\n",
    "\n",
    "        # Mở ảnh\n",
    "        img = Image.open(img_path)\n",
    "        \n",
    "        image = img.convert('RGB')\n",
    "        if self.transform is not None:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        # Chọn caption ngẫu nhiên\n",
    "        captions = self.annotations[img_path]\n",
    "        caption = np.random.choice(captions)\n",
    "\n",
    "        # Chuyển caption thành tensor\n",
    "        caption_tensor = self.caption_to_indices(caption)\n",
    "\n",
    "        # Lấy nhãn phân loại của ảnh\n",
    "        class_label = self.class_labels[img_path]\n",
    "        class_idx = self.class_to_idx[class_label]\n",
    "\n",
    "        # One-hot encoding cho nhãn phân loại\n",
    "        class_tensor = torch.zeros(len(self.unique_classes), dtype=torch.float)\n",
    "        class_tensor[class_idx] = 1.0\n",
    "\n",
    "        return image, caption_tensor, class_tensor, caption\n",
    "\n",
    "        return image, caption_tensor, class_tensor, caption\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-10T15:58:34.58522Z",
     "iopub.status.busy": "2025-03-10T15:58:34.584923Z",
     "iopub.status.idle": "2025-03-10T15:58:34.591281Z",
     "shell.execute_reply": "2025-03-10T15:58:34.590451Z",
     "shell.execute_reply.started": "2025-03-10T15:58:34.585197Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class EncoderCNN(nn.Module):\n",
    "    \"\"\"\n",
    "    Mô hình CNN để trích xuất đặc trưng từ ảnh\n",
    "    \"\"\"\n",
    "    def __init__(self, embed_size):\n",
    "        super(EncoderCNN, self).__init__()\n",
    "        # Sử dụng mô hình ResNet50 pretrained\n",
    "        resnet = models.resnet50(pretrained=True)\n",
    "        \n",
    "        # Loại bỏ lớp cuối cùng (fc)\n",
    "        modules = list(resnet.children())[:-1]\n",
    "        self.resnet = nn.Sequential(*modules)\n",
    "        \n",
    "        # Lớp projection để giảm chiều đặc trưng\n",
    "        self.embed = nn.Linear(resnet.fc.in_features, embed_size)\n",
    "        self.bn = nn.BatchNorm1d(embed_size)\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        \n",
    "        # Freezing các lớp của ResNet\n",
    "        for param in self.resnet.parameters():\n",
    "            param.requires_grad = False\n",
    "            \n",
    "    def forward(self, images):\n",
    "        # Trích xuất đặc trưng với ResNet\n",
    "        with torch.no_grad():\n",
    "            features = self.resnet(images)\n",
    "        \n",
    "        # Reshape đặc trưng\n",
    "        features = features.view(features.size(0), -1)\n",
    "        \n",
    "        # Chiếu đặc trưng về không gian embed_size\n",
    "        features = self.embed(features)\n",
    "        features = self.bn(features)\n",
    "        features = self.dropout(features)\n",
    "        \n",
    "        return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-10T15:58:37.238036Z",
     "iopub.status.busy": "2025-03-10T15:58:37.237704Z",
     "iopub.status.idle": "2025-03-10T15:58:37.243916Z",
     "shell.execute_reply": "2025-03-10T15:58:37.24314Z",
     "shell.execute_reply.started": "2025-03-10T15:58:37.238007Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class DecoderRNN(nn.Module):\n",
    "    \"\"\"\n",
    "    Mô hình LSTM để sinh caption từ đặc trưng ảnh\n",
    "    \"\"\"\n",
    "    def __init__(self, embed_size, hidden_size, vocab_size, num_layers=1):\n",
    "        super(DecoderRNN, self).__init__()\n",
    "        \n",
    "        # Lớp embedding cho các từ\n",
    "        self.embed = nn.Embedding(vocab_size, embed_size)\n",
    "        \n",
    "        # LSTM layer\n",
    "        self.lstm = nn.LSTM(embed_size, hidden_size, num_layers, batch_first=True)\n",
    "        \n",
    "        # Lớp fully connected để dự đoán từ tiếp theo\n",
    "        self.linear = nn.Linear(hidden_size, vocab_size)\n",
    "        \n",
    "        # Dropout\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        \n",
    "    def forward(self, features, captions):\n",
    "        # Embedding captions\n",
    "        embeddings = self.embed(captions)\n",
    "        \n",
    "        # Ghép đặc trưng ảnh với embedding của caption\n",
    "        # features: (batch_size, embed_size)\n",
    "        # embeddings: (batch_size, caption_length, embed_size)\n",
    "        features = features.unsqueeze(1)  # (batch_size, 1, embed_size)\n",
    "        \n",
    "        # Ghép đặc trưng ảnh với tất cả các từ trừ từ cuối cùng\n",
    "        embeddings = torch.cat((features, embeddings[:, :-1, :]), dim=1)\n",
    "        \n",
    "        # Đưa qua LSTM\n",
    "        hiddens, _ = self.lstm(embeddings)\n",
    "        \n",
    "        # Đưa qua lớp fully connected\n",
    "        outputs = self.linear(hiddens)\n",
    "        \n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-10T15:58:43.267855Z",
     "iopub.status.busy": "2025-03-10T15:58:43.267503Z",
     "iopub.status.idle": "2025-03-10T15:58:43.272801Z",
     "shell.execute_reply": "2025-03-10T15:58:43.272072Z",
     "shell.execute_reply.started": "2025-03-10T15:58:43.267828Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class ClassificationHead(nn.Module):\n",
    "    \"\"\"\n",
    "    Mô hình phân loại ảnh từ đặc trưng ảnh\n",
    "    \"\"\"\n",
    "    def __init__(self, embed_size, num_classes):\n",
    "        super(ClassificationHead, self).__init__()\n",
    "        \n",
    "        # Các lớp fully connected\n",
    "        self.fc1 = nn.Linear(embed_size, 512)\n",
    "        self.fc2 = nn.Linear(512, num_classes)\n",
    "        \n",
    "        # Các lớp khác\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        \n",
    "    def forward(self, features):\n",
    "        # Đưa đặc trưng qua các lớp fully connected\n",
    "        x = self.fc1(features)\n",
    "        x = self.relu(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc2(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-10T15:58:45.762526Z",
     "iopub.status.busy": "2025-03-10T15:58:45.762239Z",
     "iopub.status.idle": "2025-03-10T15:58:45.767471Z",
     "shell.execute_reply": "2025-03-10T15:58:45.766642Z",
     "shell.execute_reply.started": "2025-03-10T15:58:45.762503Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class MultitaskModel(nn.Module):\n",
    "    \"\"\"\n",
    "    Mô hình multitask học đồng thời phân loại và sinh caption\n",
    "    \"\"\"\n",
    "    def __init__(self, embed_size, hidden_size, vocab_size, num_classes):\n",
    "        super(MultitaskModel, self).__init__()\n",
    "        \n",
    "        # CNN encoder\n",
    "        self.encoder = EncoderCNN(embed_size)\n",
    "        \n",
    "        # LSTM decoder cho sinh caption\n",
    "        self.decoder = DecoderRNN(embed_size, hidden_size, vocab_size)\n",
    "        \n",
    "        # Classification head cho phân loại\n",
    "        self.classifier = ClassificationHead(embed_size, num_classes)\n",
    "        \n",
    "    def forward(self, images, captions):\n",
    "        # Trích xuất đặc trưng từ ảnh\n",
    "        features = self.encoder(images)\n",
    "        \n",
    "        # Task 1: Phân loại\n",
    "        classification_outputs = self.classifier(features)\n",
    "        \n",
    "        # Task 2: Sinh caption\n",
    "        caption_outputs = self.decoder(features, captions)\n",
    "        \n",
    "        return classification_outputs, caption_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-10T15:58:47.860653Z",
     "iopub.status.busy": "2025-03-10T15:58:47.860315Z",
     "iopub.status.idle": "2025-03-10T15:58:47.86811Z",
     "shell.execute_reply": "2025-03-10T15:58:47.867211Z",
     "shell.execute_reply.started": "2025-03-10T15:58:47.860624Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def train_model(model, train_loader, criterion_cls, criterion_cap, optimizer, num_epochs=10, device='cuda'):\n",
    "    \"\"\"\n",
    "    Huấn luyện mô hình multitask\n",
    "    \"\"\"\n",
    "    model.train()\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        running_loss = 0.0\n",
    "        running_cls_acc = 0.0\n",
    "        running_cap_acc = 0.0\n",
    "        \n",
    "        for i, (images, captions, class_labels, _) in enumerate(tqdm(train_loader)):\n",
    "            # Chuyển dữ liệu sang device\n",
    "            images = images.to(device)\n",
    "            captions = captions.to(device)\n",
    "            class_labels = class_labels.to(device)\n",
    "            \n",
    "            # Xóa gradient\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # Forward pass\n",
    "            cls_outputs, cap_outputs = model(images, captions)\n",
    "            \n",
    "            # Tính loss cho task phân loại\n",
    "            cls_loss = criterion_cls(cls_outputs, class_labels)\n",
    "            \n",
    "            # Tính loss cho task sinh caption\n",
    "            # Reshape cap_outputs và captions cho CrossEntropyLoss\n",
    "            cap_outputs = cap_outputs.view(-1, cap_outputs.size(2))\n",
    "            captions = captions.view(-1)\n",
    "            cap_loss = criterion_cap(cap_outputs, captions)\n",
    "            \n",
    "            # Tổng hợp loss\n",
    "            loss = 0.4 * cls_loss + 0.6 * cap_loss\n",
    "            \n",
    "            # Backward pass\n",
    "            loss.backward()\n",
    "            \n",
    "            # Cập nhật trọng số\n",
    "            optimizer.step()\n",
    "            \n",
    "            # Thống kê\n",
    "            running_loss += loss.item()\n",
    "            \n",
    "            # Tính accuracy cho phân loại\n",
    "            _, predicted_cls = torch.max(cls_outputs.data, 1)\n",
    "            _, true_cls = torch.max(class_labels.data, 1)\n",
    "            cls_acc = (predicted_cls == true_cls).float().mean()\n",
    "            running_cls_acc += cls_acc.item()\n",
    "            \n",
    "            # Tính accuracy cho sinh caption\n",
    "            _, predicted_cap = torch.max(cap_outputs.data, 1)\n",
    "            cap_acc = (predicted_cap == captions).float().mean()\n",
    "            running_cap_acc += cap_acc.item()\n",
    "            \n",
    "            # In thông tin sau mỗi 100 batch\n",
    "            if (i+1) % 100 == 0:\n",
    "                print(f'Epoch [{epoch+1}/{num_epochs}], Step [{i+1}/{len(train_loader)}], '\n",
    "                      f'Loss: {loss.item():.4f}, Cls Acc: {cls_acc.item():.4f}, Cap Acc: {cap_acc.item():.4f}')\n",
    "        \n",
    "        # In thông tin sau mỗi epoch\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {running_loss/len(train_loader):.4f}, '\n",
    "              f'Cls Acc: {running_cls_acc/len(train_loader):.4f}, Cap Acc: {running_cap_acc/len(train_loader):.4f}')\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-10T15:59:59.133288Z",
     "iopub.status.busy": "2025-03-10T15:59:59.132989Z",
     "iopub.status.idle": "2025-03-10T15:59:59.141159Z",
     "shell.execute_reply": "2025-03-10T15:59:59.140357Z",
     "shell.execute_reply.started": "2025-03-10T15:59:59.133264Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def predict_caption(model, image_path, vocab, transform, max_length=50, device='cuda'):\n",
    "    \"\"\"\n",
    "    Dự đoán caption cho một ảnh mới\n",
    "    \"\"\"\n",
    "    # Tiền xử lý ảnh\n",
    "    image = Image.open(image_path).convert('RGB')\n",
    "    image = transform(image).unsqueeze(0).to(device)\n",
    "    \n",
    "    # Tắt chế độ training\n",
    "    model.eval()\n",
    "    \n",
    "    # Tạo từ điển ngược để chuyển từ index sang từ\n",
    "    idx_to_word = {idx: word for word, idx in vocab.items()}\n",
    "    \n",
    "    # Bắt đầu với token <start>\n",
    "    start_token = torch.tensor([vocab['<start>']]).unsqueeze(0).to(device)\n",
    "    \n",
    "    # Trích xuất đặc trưng từ ảnh\n",
    "    with torch.no_grad():\n",
    "        features = model.encoder(image)\n",
    "        \n",
    "        # Dự đoán phân loại\n",
    "        cls_outputs = model.classifier(features)\n",
    "        _, predicted_cls = torch.max(cls_outputs.data, 1)\n",
    "        \n",
    "        # Dự đoán caption\n",
    "        captions = []\n",
    "        input_word = start_token\n",
    "        \n",
    "        # Chuẩn bị hidden state cho LSTM\n",
    "        h = torch.zeros(1, 1, model.decoder.lstm.hidden_size).to(device)\n",
    "        c = torch.zeros(1, 1, model.decoder.lstm.hidden_size).to(device)\n",
    "        \n",
    "        # Sinh từng từ một cho đến khi gặp token <end> hoặc đạt max_length\n",
    "        for i in range(max_length):\n",
    "            embeddings = model.decoder.embed(input_word).squeeze(0)\n",
    "            \n",
    "            # Ghép với đặc trưng ảnh cho từ đầu tiên\n",
    "            if i == 0:\n",
    "                embeddings = features\n",
    "            \n",
    "            # Reshape cho LSTM\n",
    "            embeddings = embeddings.unsqueeze(0).unsqueeze(0)\n",
    "            \n",
    "            # Dự đoán từ tiếp theo\n",
    "            lstm_out, (h, c) = model.decoder.lstm(embeddings, (h, c))\n",
    "            outputs = model.decoder.linear(lstm_out.squeeze(0))\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            \n",
    "            # Thêm từ vào caption\n",
    "            word_idx = predicted.item()\n",
    "            captions.append(word_idx)\n",
    "            \n",
    "            # Nếu gặp token <end>, dừng lại\n",
    "            if word_idx == vocab['<end>']:\n",
    "                break\n",
    "            \n",
    "            # Cập nhật input_word cho bước tiếp theo\n",
    "            input_word = predicted.unsqueeze(0)\n",
    "    \n",
    "    # Chuyển từ indices sang từ\n",
    "    caption = ' '.join([idx_to_word[idx] for idx in captions if idx not in [vocab['<start>'], vocab['<end>'], vocab['<pad>']]])\n",
    "    \n",
    "    return predicted_cls.item(), caption"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-10T16:12:31.473792Z",
     "iopub.status.busy": "2025-03-10T16:12:31.473455Z",
     "iopub.status.idle": "2025-03-10T16:12:31.480883Z",
     "shell.execute_reply": "2025-03-10T16:12:31.479945Z",
     "shell.execute_reply.started": "2025-03-10T16:12:31.473765Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def main():\n",
    "    # Thiết lập các tham số\n",
    "    embed_size = 256\n",
    "    hidden_size = 512\n",
    "    batch_size = 32\n",
    "    num_epochs = 100\n",
    "    learning_rate = 0.001\n",
    "    \n",
    "    # Thiết lập device\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    \n",
    "    # Tiền xử lý ảnh\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "    \n",
    "    # Tạo dataset\n",
    "    dataset = ImageCaptionDataset(image_root=\"/kaggle/input/imagecaptioning\", captions_file='/kaggle/input/imagecaptioning/output.json', transform=transform)\n",
    "    \n",
    "    # Chia dataset\n",
    "    train_size = int(0.8 * len(dataset))\n",
    "    val_size = len(dataset) - train_size\n",
    "    train_dataset, val_dataset = torch.utils.data.random_split(dataset, [train_size, val_size])\n",
    "    \n",
    "    # Tạo dataloader\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=4)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=4)\n",
    "    \n",
    "    # Tạo mô hình\n",
    "    vocab_size = len(dataset.vocab)\n",
    "    num_classes = len(dataset.unique_classes)\n",
    "    model = MultitaskModel(embed_size, hidden_size, vocab_size, num_classes).to(device)\n",
    "    \n",
    "    # Định nghĩa loss function và optimizer\n",
    "    criterion_cls = nn.BCEWithLogitsLoss()  # Binary Cross Entropy cho phân loại\n",
    "    criterion_cap = nn.CrossEntropyLoss(ignore_index=dataset.vocab['<pad>'])  # Cross Entropy cho sinh caption\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    \n",
    "    # Huấn luyện mô hình\n",
    "    model = train_model(model, train_loader, criterion_cls, criterion_cap, optimizer, num_epochs, device)\n",
    "    \n",
    "    # Lưu mô hình\n",
    "    torch.save(model.state_dict(), 'multitask_model.pth')\n",
    "    \n",
    "    # Lưu vocabulary\n",
    "    with open('vocab.pkl', 'wb') as f:\n",
    "        pickle.dump(dataset.vocab, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-10T16:15:50.551266Z",
     "iopub.status.busy": "2025-03-10T16:15:50.550935Z",
     "iopub.status.idle": "2025-03-10T16:36:06.206453Z",
     "shell.execute_reply": "2025-03-10T16:36:06.205346Z",
     "shell.execute_reply.started": "2025-03-10T16:15:50.551241Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "  # Dự đoán caption cho một ảnh mới\n",
    "    test_image_path = 'path/to/test/image.jpg'\n",
    "    predicted_class, caption = predict_caption(model, test_image_path, dataset.vocab, transform, device=device)\n",
    "    print(f'Predicted class: {dataset.unique_classes[predicted_class]}')\n",
    "    print(f'Generated caption: {caption}')"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 6834498,
     "sourceId": 10981942,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30918,
   "isGpuEnabled": false,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
